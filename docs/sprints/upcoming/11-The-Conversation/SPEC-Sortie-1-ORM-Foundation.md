# Technical Specification: SQLAlchemy Foundation & ORM Models

**Sprint**: Sprint 11 "The Conversation"  
**Sortie**: 1 of 4  
**Status**: Ready for Implementation  
**Estimated Effort**: 6-8 hours  
**Dependencies**: Sprint 10 complete (test infrastructure, async database)  
**Blocking**: Sortie 2, 3, 4 (all depend on ORM models)  

---

## Overview

**Purpose**: Establish SQLAlchemy ORM foundation by creating 8 database models, initializing Alembic migrations, and generating the initial schema migration from v0.5.0 SQLite schema. This sortie provides the type-safe model layer that Sortie 2 will integrate into BotDatabase.

**Scope**: 
- Install SQLAlchemy 2.0+, Alembic, async drivers (aiosqlite, asyncpg)
- Create `common/models.py` with 8 ORM models matching current schema
- Initialize Alembic migration framework
- Generate and test initial migration (v0.5.0 â†’ v0.6.0)
- Verify migration applies cleanly and rolls back successfully
- Document model relationships and constraints

**Non-Goals**: 
- Integrating models into BotDatabase (Sortie 2)
- PostgreSQL testing (Sortie 3)
- Data migration from existing databases (handled automatically by Alembic)
- Query optimization (future sprint)
- Model relationships/foreign keys (keep simple for v0.6.0)

---

## 1. Requirements

### 1.1 Functional Requirements

**FR-001**: SQLAlchemy 2.0+ MUST be installed with async support  
**FR-002**: 8 ORM models MUST match current v0.5.0 schema exactly  
**FR-003**: All models MUST have complete type hints  
**FR-004**: Alembic MUST be initialized and configured  
**FR-005**: Initial migration MUST generate from models  
**FR-006**: Migration MUST apply cleanly (`alembic upgrade head`)  
**FR-007**: Migration MUST rollback cleanly (`alembic downgrade base`)  
**FR-008**: Models MUST support both SQLite and PostgreSQL  

### 1.2 Non-Functional Requirements

**NFR-001**: Model definitions <300 lines total (keep simple)  
**NFR-002**: Migration generation <1 minute  
**NFR-003**: Type hints pass `mypy --strict` validation  
**NFR-004**: Models self-documenting (clear docstrings)  
**NFR-005**: Alembic config uses environment variables (secure)  

---

## 2. Problem Statement

### 2.1 Current Database Schema

**File**: `common/database.py` (938 lines)  
**Tables**: 8 tables defined via raw SQL `CREATE TABLE` statements

```python
# Lines 39-179: Table creation in _create_tables()
cursor.execute('''
    CREATE TABLE IF NOT EXISTS user_stats (
        username TEXT PRIMARY KEY,
        first_seen INTEGER NOT NULL,
        last_seen INTEGER NOT NULL,
        total_chat_lines INTEGER DEFAULT 0,
        total_time_connected INTEGER DEFAULT 0,
        current_session_start INTEGER
    )
''')

cursor.execute('''
    CREATE TABLE IF NOT EXISTS user_actions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        timestamp INTEGER NOT NULL,
        username TEXT NOT NULL,
        action_type TEXT NOT NULL,
        details TEXT
    )
''')

# ... 6 more tables ...
```

**Problems**:
1. **No Type Safety**: SQL is strings - typos discovered at runtime
2. **No Schema Versioning**: Changes require manual ALTER TABLE statements
3. **No Database Portability**: SQLite-specific syntax (AUTOINCREMENT, TEXT)
4. **Hard to Maintain**: Schema scattered across 140 lines of SQL
5. **No IDE Support**: Can't autocomplete table/column names

### 2.2 Target ORM Structure

**File**: `common/models.py` (NEW - ~300 lines)  
**Tables**: 8 ORM models with type hints and relationships

```python
from sqlalchemy import Column, Integer, String, Text, Boolean, Index
from sqlalchemy.ext.asyncio import AsyncAttrs
from sqlalchemy.orm import DeclarativeBase

class Base(AsyncAttrs, DeclarativeBase):
    """Base for all ORM models - enables async operations"""
    pass

class UserStats(Base):
    __tablename__ = 'user_stats'
    
    username: Mapped[str] = mapped_column(String(50), primary_key=True)
    first_seen: Mapped[int] = mapped_column(Integer, nullable=False)
    last_seen: Mapped[int] = mapped_column(Integer, nullable=False)
    total_chat_lines: Mapped[int] = mapped_column(Integer, default=0)
    total_time_connected: Mapped[int] = mapped_column(Integer, default=0)
    current_session_start: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)
```

**Benefits**:
- âœ… Type-safe: IDE autocompletes, mypy validates
- âœ… Self-documenting: Models define schema clearly
- âœ… Portable: Works with SQLite, PostgreSQL, MySQL
- âœ… Maintainable: Single source of truth for schema
- âœ… Versionable: Alembic tracks changes

---

## 3. Detailed Design

### 3.1 Dependencies

**Core Dependencies** (add to `requirements.txt`):

```txt
# Database ORM and migrations (Sprint 11)
sqlalchemy[asyncio]==2.0.23          # ORM with async support
alembic==1.13.1                      # Database migrations
aiosqlite==0.19.0                    # Async SQLite driver
asyncpg==0.29.0                      # Async PostgreSQL driver
greenlet==3.0.3                      # Required for SQLAlchemy async
```

**Why These Versions**:
- **SQLAlchemy 2.0.23**: Latest stable, full async support, type hints
- **Alembic 1.13.1**: Latest stable, SQLAlchemy 2.0 compatible
- **aiosqlite 0.19.0**: Production-ready async SQLite
- **asyncpg 0.29.0**: Fastest PostgreSQL driver
- **greenlet 3.0.3**: SQLAlchemy async dependency

### 3.2 ORM Model Architecture

**File Structure**:
```
common/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config.py
â”œâ”€â”€ database.py          # Will be updated in Sortie 2
â”œâ”€â”€ models.py            # NEW - ORM models
â”œâ”€â”€ shell.py
â””â”€â”€ database_service.py
```

**Model Hierarchy**:
```
Base (DeclarativeBase + AsyncAttrs)
â”œâ”€â”€ UserStats          # User activity tracking
â”œâ”€â”€ UserAction         # Audit log
â”œâ”€â”€ ChannelStats       # Channel-wide stats
â”œâ”€â”€ UserCountHistory   # Historical counts
â”œâ”€â”€ RecentChat         # Message cache
â”œâ”€â”€ CurrentStatus      # Bot status (singleton)
â”œâ”€â”€ OutboundMessage    # Message queue
â””â”€â”€ ApiToken           # API authentication
```

### 3.3 Alembic Structure

**Directory Layout**:
```
alembic/
â”œâ”€â”€ versions/          # Migration files
â”‚   â””â”€â”€ 001_<hash>_initial_schema.py
â”œâ”€â”€ env.py            # Alembic environment config
â”œâ”€â”€ script.py.mako    # Migration template
â””â”€â”€ README           # Migration instructions

alembic.ini           # Alembic configuration
```

**Migration Workflow**:
```
1. Developer changes model (add column, index, etc.)
2. Run: alembic revision --autogenerate -m "Description"
3. Review generated migration file
4. Test: alembic upgrade head
5. Test rollback: alembic downgrade -1
6. Commit migration + model changes
```

---

## 4. Implementation Changes

### Change 1: Add Dependencies to requirements.txt

**File**: `requirements.txt`  
**Location**: Root directory  

**Addition** (after existing database section):
```txt
# Database (v0.5.0 - SQLite)
# REMOVED: Direct sqlite3 usage (Python stdlib)

# Database ORM and Migrations (v0.6.0 - Sprint 11)
sqlalchemy[asyncio]==2.0.23          # ORM framework with async support
alembic==1.13.1                      # Database schema migrations
aiosqlite==0.19.0                    # Async SQLite driver for development
asyncpg==0.29.0                      # Async PostgreSQL driver for production
greenlet==3.0.3                      # Required for SQLAlchemy async operations
psycopg2-binary==2.9.9              # Fallback sync PostgreSQL driver
```

**Rationale**: All dependencies for SQLAlchemy + Alembic + async drivers

---

### Change 2: Create ORM Models File

**File**: `common/models.py` (NEW FILE)  
**Location**: `common/`  

**Complete Implementation**:

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SQLAlchemy ORM Models for Rosey Bot
====================================

Defines database schema using SQLAlchemy 2.0 ORM with type hints.

Models correspond to v0.5.0 schema:
- UserStats: User activity tracking
- UserAction: Audit log for PM commands, moderation
- ChannelStats: Channel-wide statistics
- UserCountHistory: Historical user count tracking
- RecentChat: Recent chat message cache (rolling window)
- CurrentStatus: Current bot status (singleton pattern)
- OutboundMessage: Queued outbound messages
- ApiToken: API authentication tokens

Usage:
    from common.models import Base, UserStats, UserAction
    
    # Create engine
    engine = create_async_engine('sqlite+aiosqlite:///bot_data.db')
    
    # Create tables
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    
    # Query
    async with AsyncSession(engine) as session:
        result = await session.execute(
            select(UserStats).where(UserStats.username == 'Alice')
        )
        user = result.scalar_one_or_none()

Migration History:
    v0.5.0: Raw SQL schema (sqlite3)
    v0.6.0: SQLAlchemy ORM (Sprint 11 Sortie 1)
"""

from typing import Optional
from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    Boolean,
    Index,
    CheckConstraint
)
from sqlalchemy.ext.asyncio import AsyncAttrs
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column


# ============================================================================
# Base Class
# ============================================================================

class Base(AsyncAttrs, DeclarativeBase):
    """
    Base class for all ORM models.
    
    Attributes:
        AsyncAttrs: Enables async attribute loading (SQLAlchemy 2.0)
        DeclarativeBase: Base for declarative model definitions
    
    Usage:
        class MyModel(Base):
            __tablename__ = 'my_table'
            id: Mapped[int] = mapped_column(Integer, primary_key=True)
    """
    pass


# ============================================================================
# User Statistics
# ============================================================================

class UserStats(Base):
    """
    Tracks user activity and connection time.
    
    Primary use: Bot statistics, user profiles, activity tracking
    
    Schema matches v0.5.0 user_stats table exactly.
    """
    __tablename__ = 'user_stats'
    
    # Primary key
    username: Mapped[str] = mapped_column(
        String(50),
        primary_key=True,
        comment="CyTube username (case-sensitive)"
    )
    
    # Timestamps (Unix epoch seconds)
    first_seen: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        comment="First time user joined channel (Unix timestamp)"
    )
    
    last_seen: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        index=True,  # Frequently queried for "recent users"
        comment="Last time user was seen (Unix timestamp)"
    )
    
    # Activity counters
    total_chat_lines: Mapped[int] = mapped_column(
        Integer,
        default=0,
        server_default='0',
        comment="Total chat messages sent"
    )
    
    total_time_connected: Mapped[int] = mapped_column(
        Integer,
        default=0,
        server_default='0',
        comment="Total seconds connected to channel"
    )
    
    # Session tracking
    current_session_start: Mapped[Optional[int]] = mapped_column(
        Integer,
        nullable=True,
        comment="Current session start time (None if offline)"
    )
    
    # Table-level constraints and indexes
    __table_args__ = (
        Index('idx_last_seen', 'last_seen'),
        CheckConstraint('total_chat_lines >= 0', name='check_positive_lines'),
        CheckConstraint('total_time_connected >= 0', name='check_positive_time'),
        {'comment': 'User activity tracking and statistics'}
    )
    
    def __repr__(self) -> str:
        return (
            f"<UserStats(username='{self.username}', "
            f"last_seen={self.last_seen}, "
            f"total_chat_lines={self.total_chat_lines})>"
        )


# ============================================================================
# User Actions (Audit Log)
# ============================================================================

class UserAction(Base):
    """
    Audit log for user actions (PM commands, moderation, etc.).
    
    Primary use: Security auditing, PM command logging, compliance
    
    Schema matches v0.5.0 user_actions table exactly.
    """
    __tablename__ = 'user_actions'
    
    # Primary key
    id: Mapped[int] = mapped_column(
        Integer,
        primary_key=True,
        autoincrement=True,
        comment="Unique action ID"
    )
    
    # Action metadata
    timestamp: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        index=True,  # Frequently queried for recent actions
        comment="Action timestamp (Unix epoch)"
    )
    
    username: Mapped[str] = mapped_column(
        String(50),
        nullable=False,
        index=True,  # Frequently queried for user audit
        comment="Username performing action"
    )
    
    action_type: Mapped[str] = mapped_column(
        String(50),
        nullable=False,
        comment="Action type (e.g., 'pm_command', 'kick', 'ban')"
    )
    
    details: Mapped[Optional[str]] = mapped_column(
        Text,
        nullable=True,
        comment="Action details (JSON or plain text)"
    )
    
    # Table-level constraints and indexes
    __table_args__ = (
        Index('idx_timestamp', 'timestamp'),
        Index('idx_username', 'username'),
        Index('idx_username_timestamp', 'username', 'timestamp'),  # Compound index
        {'comment': 'Audit log for user actions and PM commands'}
    )
    
    def __repr__(self) -> str:
        return (
            f"<UserAction(id={self.id}, "
            f"username='{self.username}', "
            f"action_type='{self.action_type}')>"
        )


# ============================================================================
# Channel Statistics
# ============================================================================

class ChannelStats(Base):
    """
    Channel-wide statistics (high water mark, etc.).
    
    Primary use: Channel metrics, bot dashboard
    
    Note: Singleton table (id always = 1)
    Schema matches v0.5.0 channel_stats table exactly.
    """
    __tablename__ = 'channel_stats'
    
    # Primary key (singleton)
    id: Mapped[int] = mapped_column(
        Integer,
        primary_key=True,
        default=1,
        comment="Always 1 (singleton table)"
    )
    
    # Statistics
    max_users: Mapped[int] = mapped_column(
        Integer,
        default=0,
        server_default='0',
        comment="High water mark - maximum concurrent users"
    )
    
    last_updated: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        comment="Last update timestamp (Unix epoch)"
    )
    
    # Table-level constraints
    __table_args__ = (
        CheckConstraint('id = 1', name='check_singleton'),
        CheckConstraint('max_users >= 0', name='check_positive_users'),
        {'comment': 'Channel-wide statistics (singleton table)'}
    )
    
    def __repr__(self) -> str:
        return f"<ChannelStats(max_users={self.max_users})>"


# ============================================================================
# User Count History
# ============================================================================

class UserCountHistory(Base):
    """
    Historical user count tracking for graphing and analysis.
    
    Primary use: Charts, analytics, trend analysis
    
    Schema matches v0.5.0 user_count_history table exactly.
    """
    __tablename__ = 'user_count_history'
    
    # Primary key
    id: Mapped[int] = mapped_column(
        Integer,
        primary_key=True,
        autoincrement=True,
        comment="Unique history entry ID"
    )
    
    # Timestamp
    timestamp: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        index=True,  # Frequently queried for time ranges
        comment="Sample timestamp (Unix epoch)"
    )
    
    # User counts
    chat_users: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        comment="Number of chat-enabled users"
    )
    
    connected_users: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        comment="Total connected users (including guests)"
    )
    
    # Table-level constraints and indexes
    __table_args__ = (
        Index('idx_timestamp', 'timestamp'),
        CheckConstraint('chat_users >= 0', name='check_positive_chat_users'),
        CheckConstraint('connected_users >= 0', name='check_positive_connected'),
        CheckConstraint('connected_users >= chat_users', name='check_connected_ge_chat'),
        {'comment': 'Historical user count tracking for analytics'}
    )
    
    def __repr__(self) -> str:
        return (
            f"<UserCountHistory(timestamp={self.timestamp}, "
            f"chat={self.chat_users}, connected={self.connected_users})>"
        )


# ============================================================================
# Recent Chat Cache
# ============================================================================

class RecentChat(Base):
    """
    Recent chat message cache (rolling window).
    
    Primary use: Recent chat history API, message replay
    
    Schema matches v0.5.0 recent_chat table exactly.
    """
    __tablename__ = 'recent_chat'
    
    # Primary key
    id: Mapped[int] = mapped_column(
        Integer,
        primary_key=True,
        autoincrement=True,
        comment="Unique message ID"
    )
    
    # Message metadata
    timestamp: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        index=True,  # Frequently queried for recent messages
        comment="Message timestamp (Unix epoch)"
    )
    
    username: Mapped[str] = mapped_column(
        String(50),
        nullable=False,
        comment="Username who sent message"
    )
    
    message: Mapped[str] = mapped_column(
        Text,
        nullable=False,
        comment="Chat message content"
    )
    
    # Table-level constraints and indexes
    __table_args__ = (
        Index('idx_timestamp', 'timestamp'),
        {'comment': 'Recent chat message cache (rolling window)'}
    )
    
    def __repr__(self) -> str:
        msg_preview = self.message[:30] + '...' if len(self.message) > 30 else self.message
        return (
            f"<RecentChat(username='{self.username}', "
            f"message='{msg_preview}')>"
        )


# ============================================================================
# Current Status (Bot Status)
# ============================================================================

class CurrentStatus(Base):
    """
    Current bot status (online/offline, current users, etc.).
    
    Primary use: Bot dashboard, status API, health checks
    
    Note: Singleton table (id always = 1)
    Schema matches v0.5.0 current_status table exactly.
    """
    __tablename__ = 'current_status'
    
    # Primary key (singleton)
    id: Mapped[int] = mapped_column(
        Integer,
        primary_key=True,
        default=1,
        comment="Always 1 (singleton table)"
    )
    
    # Status fields
    last_updated: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        comment="Last status update timestamp (Unix epoch)"
    )
    
    status: Mapped[str] = mapped_column(
        String(50),
        default='offline',
        server_default='offline',
        comment="Bot status (online/offline/connecting)"
    )
    
    current_users: Mapped[int] = mapped_column(
        Integer,
        default=0,
        server_default='0',
        comment="Current chat-enabled users"
    )
    
    connected_users: Mapped[int] = mapped_column(
        Integer,
        default=0,
        server_default='0',
        comment="Current total connected users"
    )
    
    # Table-level constraints
    __table_args__ = (
        CheckConstraint('id = 1', name='check_singleton'),
        CheckConstraint('current_users >= 0', name='check_positive_current'),
        CheckConstraint('connected_users >= 0', name='check_positive_connected'),
        {'comment': 'Current bot status (singleton table)'}
    )
    
    def __repr__(self) -> str:
        return (
            f"<CurrentStatus(status='{self.status}', "
            f"current_users={self.current_users})>"
        )


# ============================================================================
# Outbound Messages Queue
# ============================================================================

class OutboundMessage(Base):
    """
    Queued outbound messages (for send rate limiting).
    
    Primary use: Message queue, rate limiting, retry logic
    
    Schema matches v0.5.0 outbound_messages table exactly.
    """
    __tablename__ = 'outbound_messages'
    
    # Primary key
    id: Mapped[int] = mapped_column(
        Integer,
        primary_key=True,
        autoincrement=True,
        comment="Unique message queue ID"
    )
    
    # Message metadata
    timestamp: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        index=True,  # Frequently queried for queue processing
        comment="Message queued timestamp (Unix epoch)"
    )
    
    message: Mapped[str] = mapped_column(
        Text,
        nullable=False,
        comment="Message content to send"
    )
    
    # Queue state
    sent: Mapped[bool] = mapped_column(
        Boolean,
        default=False,
        server_default='0',
        index=True,  # Frequently queried for unsent messages
        comment="Whether message has been sent"
    )
    
    # Retry tracking (added in v0.5.0)
    retry_count: Mapped[int] = mapped_column(
        Integer,
        default=0,
        server_default='0',
        comment="Number of send attempts"
    )
    
    error_message: Mapped[Optional[str]] = mapped_column(
        Text,
        nullable=True,
        comment="Error message if send failed"
    )
    
    # Table-level constraints and indexes
    __table_args__ = (
        Index('idx_timestamp', 'timestamp'),
        Index('idx_sent', 'sent'),
        Index('idx_sent_timestamp', 'sent', 'timestamp'),  # Compound index
        CheckConstraint('retry_count >= 0', name='check_positive_retries'),
        {'comment': 'Outbound message queue for rate limiting'}
    )
    
    def __repr__(self) -> str:
        msg_preview = self.message[:30] + '...' if len(self.message) > 30 else self.message
        return (
            f"<OutboundMessage(id={self.id}, sent={self.sent}, "
            f"message='{msg_preview}')>"
        )


# ============================================================================
# API Tokens
# ============================================================================

class ApiToken(Base):
    """
    API authentication tokens for web API access.
    
    Primary use: API authentication, permission management
    
    Schema matches v0.5.0 api_tokens table exactly.
    """
    __tablename__ = 'api_tokens'
    
    # Primary key
    id: Mapped[int] = mapped_column(
        Integer,
        primary_key=True,
        autoincrement=True,
        comment="Unique token ID"
    )
    
    # Token
    token: Mapped[str] = mapped_column(
        String(255),
        unique=True,
        nullable=False,
        index=True,  # Frequently queried for auth
        comment="API authentication token (UUID or similar)"
    )
    
    # Token metadata
    name: Mapped[str] = mapped_column(
        String(100),
        nullable=False,
        comment="Human-readable token name"
    )
    
    permissions: Mapped[str] = mapped_column(
        Text,
        nullable=False,
        comment="JSON string of permissions"
    )
    
    # Timestamps
    created_at: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        comment="Token creation timestamp (Unix epoch)"
    )
    
    last_used: Mapped[Optional[int]] = mapped_column(
        Integer,
        nullable=True,
        comment="Last usage timestamp (None if never used)"
    )
    
    # Status
    is_active: Mapped[bool] = mapped_column(
        Boolean,
        default=True,
        server_default='1',
        index=True,  # Frequently queried for active tokens
        comment="Whether token is active (can be disabled)"
    )
    
    # Table-level constraints and indexes
    __table_args__ = (
        Index('idx_token', 'token'),
        Index('idx_is_active', 'is_active'),
        Index('idx_active_tokens', 'is_active', 'token'),  # Compound index
        {'comment': 'API authentication tokens'}
    )
    
    def __repr__(self) -> str:
        token_preview = self.token[:8] + '...' if len(self.token) > 8 else self.token
        return (
            f"<ApiToken(name='{self.name}', "
            f"token='{token_preview}', active={self.is_active})>"
        )


# ============================================================================
# Utility Functions
# ============================================================================

def get_model_by_tablename(tablename: str) -> type[Base]:
    """
    Get ORM model class by table name.
    
    Args:
        tablename: Database table name (e.g., 'user_stats')
    
    Returns:
        Model class (e.g., UserStats)
    
    Raises:
        ValueError: If table name not found
    
    Example:
        >>> model_class = get_model_by_tablename('user_stats')
        >>> print(model_class.__name__)
        UserStats
    """
    for mapper in Base.registry.mappers:
        cls = mapper.class_
        if hasattr(cls, '__tablename__') and cls.__tablename__ == tablename:
            return cls
    raise ValueError(f"No model found for table: {tablename}")


def get_all_models() -> list[type[Base]]:
    """
    Get all ORM model classes.
    
    Returns:
        List of model classes
    
    Example:
        >>> models = get_all_models()
        >>> for model in models:
        ...     print(model.__tablename__)
        user_stats
        user_actions
        ...
    """
    return [mapper.class_ for mapper in Base.registry.mappers]


# ============================================================================
# Module Exports
# ============================================================================

__all__ = [
    'Base',
    'UserStats',
    'UserAction',
    'ChannelStats',
    'UserCountHistory',
    'RecentChat',
    'CurrentStatus',
    'OutboundMessage',
    'ApiToken',
    'get_model_by_tablename',
    'get_all_models',
]
```

**Rationale**: 
- Complete ORM models matching v0.5.0 schema
- Full type hints for mypy validation
- Comprehensive docstrings
- Indexes for performance
- Check constraints for data integrity
- Ready for async operations

---

### Change 3: Initialize Alembic

**Command**: `alembic init alembic`  
**Location**: Run from project root  

**Expected Output**:
```
  Creating directory alembic ... done
  Creating directory alembic/versions ... done
  Generating alembic.ini ... done
  Generating alembic/env.py ... done
  Generating alembic/README ... done
  Generating alembic/script.py.mako ... done
```

**Rationale**: Creates Alembic directory structure and config files

---

### Change 4: Configure Alembic (alembic.ini)

**File**: `alembic.ini`  
**Location**: Project root (created by `alembic init`)  

**Changes Required**:

```ini
# Line ~58: Update sqlalchemy.url to use config.json
# BEFORE:
sqlalchemy.url = driver://user:pass@localhost/dbname

# AFTER:
# Database URL loaded from environment variable (set by alembic/env.py)
sqlalchemy.url =
```

**Rationale**: Database URL will be loaded from config.json dynamically in env.py

---

### Change 5: Configure Alembic Environment (env.py)

**File**: `alembic/env.py`  
**Location**: `alembic/` (created by `alembic init`)  

**Complete Replacement**:

```python
"""
Alembic Migration Environment for Rosey Bot
============================================

This module configures Alembic to:
1. Load database URL from config.json (not hardcoded)
2. Support async SQLAlchemy operations
3. Import all ORM models for autogeneration
4. Handle both online (async) and offline migrations

Usage:
    alembic revision --autogenerate -m "Description"
    alembic upgrade head
    alembic downgrade -1
"""

import asyncio
import json
import os
from logging.config import fileConfig
from pathlib import Path

from sqlalchemy import pool
from sqlalchemy.engine import Connection
from sqlalchemy.ext.asyncio import async_engine_from_config

from alembic import context

# Import all models for autogeneration
from common.models import Base

# Alembic Config object
config = context.config

# Interpret the config file for Python logging (if present)
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Target metadata for autogeneration
target_metadata = Base.metadata


# ============================================================================
# Database URL Loading
# ============================================================================

def load_database_url_from_config() -> str:
    """
    Load database URL from config.json.
    
    Tries (in order):
    1. ROSEY_DATABASE_URL environment variable
    2. config.json (database_url field)
    3. config-test.json (fallback for tests)
    4. Default SQLite (bot_data.db)
    
    Returns:
        Database URL (e.g., 'sqlite+aiosqlite:///bot_data.db')
    """
    # 1. Check environment variable (highest priority)
    if 'ROSEY_DATABASE_URL' in os.environ:
        return os.environ['ROSEY_DATABASE_URL']
    
    # 2. Check config.json
    config_paths = [
        Path('config.json'),
        Path('config-test.json'),
        Path('../config.json'),  # For when running from alembic/
    ]
    
    for config_path in config_paths:
        if config_path.exists():
            with open(config_path, 'r') as f:
                config_data = json.load(f)
            
            # Check for database_url (v0.6.0+)
            if 'database_url' in config_data:
                url = config_data['database_url']
                # Ensure async driver
                if url.startswith('sqlite:///'):
                    url = url.replace('sqlite:///', 'sqlite+aiosqlite:///')
                elif url.startswith('postgresql://'):
                    url = url.replace('postgresql://', 'postgresql+asyncpg://')
                return url
            
            # Fallback: check for database path (v0.5.0)
            if 'database' in config_data:
                db_path = config_data['database']
                return f'sqlite+aiosqlite:///{db_path}'
    
    # 3. Default fallback
    return 'sqlite+aiosqlite:///bot_data.db'


# Load database URL
database_url = load_database_url_from_config()
config.set_main_option('sqlalchemy.url', database_url)


# ============================================================================
# Migration Functions
# ============================================================================

def run_migrations_offline() -> None:
    """
    Run migrations in 'offline' mode.
    
    This configures the context with just a URL and not an Engine,
    though an Engine is acceptable here as well. By skipping the Engine
    creation we don't even need a DBAPI to be available.
    
    Calls to context.execute() here emit the given string to the
    script output.
    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        compare_type=True,  # Detect type changes
        compare_server_default=True,  # Detect default changes
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection: Connection) -> None:
    """
    Run migrations with an active connection.
    
    Args:
        connection: Active database connection
    """
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        compare_type=True,  # Detect type changes
        compare_server_default=True,  # Detect default changes
        render_as_batch=True,  # Required for SQLite ALTER TABLE support
    )

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations() -> None:
    """
    Run migrations in 'online' mode with async engine.
    
    In this scenario we need to create an Engine and associate a
    connection with the context.
    """
    configuration = config.get_section(config.config_ini_section, {})
    configuration["sqlalchemy.url"] = database_url
    
    connectable = async_engine_from_config(
        configuration,
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,  # Don't pool connections for migrations
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


def run_migrations_online() -> None:
    """
    Run migrations in 'online' mode (async).
    
    Wrapper to run async migrations from sync context.
    """
    asyncio.run(run_async_migrations())


# ============================================================================
# Main Entry Point
# ============================================================================

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

**Rationale**:
- Loads database URL from config.json (secure, not hardcoded)
- Supports async SQLAlchemy
- Imports all models for autogeneration
- Handles both online and offline migrations
- SQLite ALTER TABLE support (render_as_batch)

---

### Change 6: Generate Initial Migration

**Command**:
```bash
alembic revision --autogenerate -m "Initial schema v0.5.0 to v0.6.0"
```

**Location**: Run from project root  

**Expected Output**:
```
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.autogenerate.compare] Detected added table 'user_stats'
INFO  [alembic.autogenerate.compare] Detected added table 'user_actions'
INFO  [alembic.autogenerate.compare] Detected added table 'channel_stats'
INFO  [alembic.autogenerate.compare] Detected added table 'user_count_history'
INFO  [alembic.autogenerate.compare] Detected added table 'recent_chat'
INFO  [alembic.autogenerate.compare] Detected added table 'current_status'
INFO  [alembic.autogenerate.compare] Detected added table 'outbound_messages'
INFO  [alembic.autogenerate.compare] Detected added table 'api_tokens'
  Generating alembic/versions/001_<hash>_initial_schema_v0_5_0_to_v0_6_0.py ... done
```

**Generated File**: `alembic/versions/001_<hash>_initial_schema_v0_5_0_to_v0_6_0.py`

**Review Generated Migration**:
```python
"""Initial schema v0.5.0 to v0.6.0

Revision ID: <hash>
Revises: 
Create Date: 2025-11-21 XX:XX:XX
"""
from alembic import op
import sqlalchemy as sa

# revision identifiers, used by Alembic
revision = '<hash>'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('user_stats',
        sa.Column('username', sa.String(length=50), nullable=False, comment='CyTube username'),
        sa.Column('first_seen', sa.Integer(), nullable=False, comment='First join timestamp'),
        # ... all columns ...
        sa.PrimaryKeyConstraint('username'),
        comment='User activity tracking and statistics'
    )
    # ... 7 more tables ...
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('api_tokens')
    op.drop_table('outbound_messages')
    # ... all tables in reverse order ...
    # ### end Alembic commands ###
```

**Manual Fixes** (if needed):
- Verify all columns present
- Check indexes created correctly
- Ensure CHECK constraints included
- Verify comments preserved

**Rationale**: Auto-generate migration from ORM models, review for accuracy

---

### Change 7: Test Migration (Upgrade)

**Command**:
```bash
# Create test database
alembic upgrade head
```

**Expected Output**:
```
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> <hash>, Initial schema v0.5.0 to v0.6.0
```

**Verification**:
```bash
# Check database schema
sqlite3 bot_data.db ".schema"

# Should show all 8 tables with correct structure
```

**Rationale**: Verify migration applies cleanly

---

### Change 8: Test Migration (Downgrade)

**Command**:
```bash
# Rollback migration
alembic downgrade base

# Re-apply (test idempotency)
alembic upgrade head
```

**Expected Output**:
```
INFO  [alembic.runtime.migration] Running downgrade <hash> -> , Initial schema v0.5.0 to v0.6.0
INFO  [alembic.runtime.migration] Running upgrade  -> <hash>, Initial schema v0.5.0 to v0.6.0
```

**Verification**:
```bash
# Check migration history
alembic history

# Should show one migration
```

**Rationale**: Verify rollback works correctly

---

## 5. Testing Strategy

### 5.1 Unit Tests (New)

**File**: `tests/unit/test_models.py` (NEW)

**Test Cases**:

```python
import pytest
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

from common.models import (
    Base,
    UserStats,
    UserAction,
    ChannelStats,
    get_all_models,
    get_model_by_tablename
)


@pytest.fixture
async def async_session():
    """Create in-memory async SQLite session for testing."""
    engine = create_async_engine('sqlite+aiosqlite:///:memory:')
    
    # Create tables
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    
    # Create session factory
    async_session_maker = sessionmaker(
        engine, class_=AsyncSession, expire_on_commit=False
    )
    
    async with async_session_maker() as session:
        yield session
    
    await engine.dispose()


@pytest.mark.asyncio
async def test_user_stats_create(async_session):
    """Test creating UserStats record."""
    user = UserStats(
        username='TestUser',
        first_seen=1700000000,
        last_seen=1700000100,
        total_chat_lines=5,
        total_time_connected=100
    )
    
    async_session.add(user)
    await async_session.commit()
    
    # Query back
    result = await async_session.execute(
        select(UserStats).where(UserStats.username == 'TestUser')
    )
    retrieved = result.scalar_one()
    
    assert retrieved.username == 'TestUser'
    assert retrieved.total_chat_lines == 5


@pytest.mark.asyncio
async def test_user_action_create(async_session):
    """Test creating UserAction (audit log) record."""
    action = UserAction(
        timestamp=1700000000,
        username='ModUser',
        action_type='pm_command',
        details='cmd=stats, result: success'
    )
    
    async_session.add(action)
    await async_session.commit()
    
    # Query back
    result = await async_session.execute(
        select(UserAction).where(UserAction.username == 'ModUser')
    )
    retrieved = result.scalar_one()
    
    assert retrieved.action_type == 'pm_command'
    assert 'stats' in retrieved.details


@pytest.mark.asyncio
async def test_channel_stats_singleton(async_session):
    """Test ChannelStats singleton behavior."""
    stats1 = ChannelStats(
        id=1,
        max_users=50,
        last_updated=1700000000
    )
    
    async_session.add(stats1)
    await async_session.commit()
    
    # Try to create second record (should fail constraint)
    stats2 = ChannelStats(
        id=2,
        max_users=60,
        last_updated=1700000100
    )
    
    async_session.add(stats2)
    
    with pytest.raises(Exception):  # Constraint violation
        await async_session.commit()


def test_get_all_models():
    """Test get_all_models utility."""
    models = get_all_models()
    
    assert len(models) == 8
    model_names = [m.__tablename__ for m in models]
    assert 'user_stats' in model_names
    assert 'user_actions' in model_names


def test_get_model_by_tablename():
    """Test get_model_by_tablename utility."""
    model = get_model_by_tablename('user_stats')
    assert model == UserStats
    
    model = get_model_by_tablename('user_actions')
    assert model == UserAction
    
    with pytest.raises(ValueError):
        get_model_by_tablename('nonexistent_table')
```

**Coverage Target**: 100% of model definitions

---

### 5.2 Integration Tests (New)

**File**: `tests/integration/test_alembic_migrations.py` (NEW)

**Test Cases**:

```python
import pytest
import subprocess
from pathlib import Path


def test_alembic_upgrade():
    """Test alembic upgrade applies cleanly."""
    result = subprocess.run(
        ['alembic', 'upgrade', 'head'],
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0
    assert 'Initial schema' in result.stdout


def test_alembic_downgrade():
    """Test alembic downgrade rolls back cleanly."""
    result = subprocess.run(
        ['alembic', 'downgrade', 'base'],
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0


def test_alembic_history():
    """Test alembic history shows migrations."""
    result = subprocess.run(
        ['alembic', 'history'],
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0
    assert 'Initial schema' in result.stdout
```

---

### 5.3 Manual Testing

**Test Scenario 1: Fresh Database**:
```bash
# Remove existing database
rm bot_data.db

# Run migration
alembic upgrade head

# Verify schema
sqlite3 bot_data.db ".schema"

# Should show all 8 tables
```

**Test Scenario 2: Migration Rollback**:
```bash
# Downgrade
alembic downgrade -1

# Check database (should be empty)
sqlite3 bot_data.db ".tables"

# Upgrade again
alembic upgrade head

# Should work idempotently
```

**Test Scenario 3: Type Hints Validation**:
```bash
# Install mypy
pip install mypy

# Run type checking
mypy common/models.py --strict

# Should pass with no errors
```

---

## 6. Implementation Steps

### Phase 1: Dependencies (30 minutes)

1. âœ… Update requirements.txt (add SQLAlchemy, Alembic, drivers)
2. âœ… Install dependencies: `pip install -r requirements.txt`
3. âœ… Verify installations: `python -c "import sqlalchemy, alembic; print('OK')"`

### Phase 2: ORM Models (2-3 hours)

4. âœ… Create `common/models.py`
5. âœ… Implement Base class
6. âœ… Implement 8 ORM models (UserStats, UserAction, etc.)
7. âœ… Add docstrings and type hints
8. âœ… Add utility functions (get_all_models, get_model_by_tablename)
9. âœ… Verify with mypy: `mypy common/models.py --strict`

### Phase 3: Alembic Setup (1-2 hours)

10. âœ… Initialize Alembic: `alembic init alembic`
11. âœ… Configure alembic.ini (remove hardcoded URL)
12. âœ… Configure alembic/env.py (load from config.json, async support)
13. âœ… Test configuration: `alembic current`

### Phase 4: Migration Generation (1 hour)

14. âœ… Generate initial migration: `alembic revision --autogenerate -m "Initial schema"`
15. âœ… Review generated migration file
16. âœ… Fix any autogeneration issues
17. âœ… Test upgrade: `alembic upgrade head`
18. âœ… Test downgrade: `alembic downgrade base`
19. âœ… Test re-upgrade: `alembic upgrade head`

### Phase 5: Testing (1-2 hours)

20. âœ… Create test_models.py (unit tests)
21. âœ… Create test_alembic_migrations.py (integration tests)
22. âœ… Run tests: `pytest tests/unit/test_models.py -v`
23. âœ… Run tests: `pytest tests/integration/test_alembic_migrations.py -v`
24. âœ… Manual testing (fresh database, rollback, type checking)

### Phase 6: Documentation (30 minutes)

25. âœ… Update ARCHITECTURE.md (add SQLAlchemy section)
26. âœ… Create alembic/README (migration instructions)
27. âœ… Update CHANGELOG.md (v0.6.0 changes)
28. âœ… Commit: "Sprint 11 Sortie 1: SQLAlchemy ORM models and Alembic setup"

---

## 7. Acceptance Criteria

### 7.1 Dependencies Installed

- [ ] SQLAlchemy 2.0.23+ installed
- [ ] Alembic 1.13.1+ installed
- [ ] aiosqlite 0.19.0+ installed
- [ ] asyncpg 0.29.0+ installed
- [ ] All imports work: `from common.models import Base, UserStats`

### 7.2 ORM Models Complete

- [ ] 8 models created matching v0.5.0 schema
- [ ] All models have type hints
- [ ] All models have docstrings
- [ ] Models pass mypy --strict validation
- [ ] Utility functions implemented
- [ ] __repr__ methods defined

### 7.3 Alembic Configuration

- [ ] Alembic initialized successfully
- [ ] alembic.ini configured (no hardcoded URL)
- [ ] alembic/env.py loads from config.json
- [ ] Async support configured
- [ ] Model imports working

### 7.4 Migration Generated

- [ ] Initial migration generated
- [ ] Migration includes all 8 tables
- [ ] Migration includes all indexes
- [ ] Migration includes check constraints
- [ ] upgrade() creates all tables
- [ ] downgrade() drops all tables

### 7.5 Migration Testing

- [ ] `alembic upgrade head` succeeds
- [ ] All 8 tables created
- [ ] Schema matches v0.5.0 exactly
- [ ] `alembic downgrade base` succeeds
- [ ] All tables dropped
- [ ] Re-upgrade works (idempotent)

### 7.6 Tests Passing

- [ ] Unit tests pass: test_models.py (8+ tests)
- [ ] Integration tests pass: test_alembic_migrations.py (3+ tests)
- [ ] Type checking passes: `mypy common/models.py --strict`
- [ ] No regressions in existing tests

### 7.7 Documentation Complete

- [ ] ARCHITECTURE.md updated (SQLAlchemy section)
- [ ] alembic/README created (migration instructions)
- [ ] CHANGELOG.md updated (v0.6.0 notes)
- [ ] common/models.py has comprehensive docstrings

---

## 8. Deliverables

### 8.1 Code Changes

**Modified Files**:
- `requirements.txt` - Add SQLAlchemy, Alembic, drivers

**New Files**:
- `common/models.py` - 8 ORM models (~750 lines)
- `alembic.ini` - Alembic configuration
- `alembic/env.py` - Migration environment (~200 lines)
- `alembic/versions/001_<hash>_initial_schema.py` - Initial migration
- `tests/unit/test_models.py` - Model unit tests (~200 lines)
- `tests/integration/test_alembic_migrations.py` - Migration tests (~50 lines)

### 8.2 Documentation

**Updated**:
- `docs/ARCHITECTURE.md` - SQLAlchemy architecture
- `docs/CHANGELOG.md` - v0.6.0 changes

**New**:
- `alembic/README` - Migration workflow guide

---

## 9. Related Issues

**Depends On**:
- Sprint 10 complete (async database foundation)

**Blocks**:
- Sortie 2: BotDatabase SQLAlchemy integration
- Sortie 3: PostgreSQL support
- Sortie 4: Documentation

**Related**:
- Sprint 11 PRD: SQLAlchemy Migration
- Sprint 10 Sortie 1: Async BotDatabase.connect()

---

## 10. Success Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| ORM Models | 8/8 complete | Code review |
| Type Hints | 100% coverage | mypy validation |
| Migration Success | 100% (up + down) | Manual testing |
| Unit Tests | 8+ passing | pytest output |
| Integration Tests | 3+ passing | pytest output |
| Documentation | Complete | Manual review |

---

## Appendix A: Model Comparison

### A.1 Raw SQL vs ORM (UserStats Example)

**v0.5.0 (Raw SQL)**:
```python
cursor.execute('''
    CREATE TABLE IF NOT EXISTS user_stats (
        username TEXT PRIMARY KEY,
        first_seen INTEGER NOT NULL,
        last_seen INTEGER NOT NULL,
        total_chat_lines INTEGER DEFAULT 0,
        total_time_connected INTEGER DEFAULT 0,
        current_session_start INTEGER
    )
''')

cursor.execute(
    'SELECT * FROM user_stats WHERE username = ?',
    (username,)
)
```

**v0.6.0 (SQLAlchemy ORM)**:
```python
class UserStats(Base):
    __tablename__ = 'user_stats'
    username: Mapped[str] = mapped_column(String(50), primary_key=True)
    first_seen: Mapped[int] = mapped_column(Integer, nullable=False)
    # ... full type safety ...

result = await session.execute(
    select(UserStats).where(UserStats.username == username)
)
user = result.scalar_one_or_none()
```

---

## Appendix B: Migration Commands Reference

```bash
# Initialize Alembic (one-time)
alembic init alembic

# Generate migration from model changes
alembic revision --autogenerate -m "Description"

# Apply all pending migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# Rollback all migrations
alembic downgrade base

# Show migration history
alembic history

# Show current migration
alembic current

# Stamp database without running migrations
alembic stamp head
```

---

**Document Version**: 1.0  
**Last Updated**: November 21, 2025  
**Author**: GitHub Copilot (Claude Sonnet 4.5)  
**Status**: Ready for Implementation âœ…

**Next Steps**:
1. Install dependencies: `pip install -r requirements.txt`
2. Create common/models.py (8 ORM models)
3. Initialize Alembic: `alembic init alembic`
4. Configure alembic/env.py (async + config loading)
5. Generate migration: `alembic revision --autogenerate`
6. Test: `alembic upgrade head` then `alembic downgrade base`
7. Write tests: test_models.py + test_alembic_migrations.py
8. Commit: "Sprint 11 Sortie 1: ORM foundation complete"

---

**"Leave the gun, take the cannoli... and the type-safe ORM models."** ðŸŽ¬
