# Technical Specification: Documentation & Deployment

**Sprint**: Sprint 11 "The Conversation"  
**Sortie**: 4 of 4  
**Status**: Ready for Implementation  
**Estimated Effort**: 2-3 hours  
**Dependencies**: Sortie 1 (ORM models), Sortie 2 (BotDatabase), Sortie 3 (PostgreSQL)  
**Blocking**: None (final sortie)  

---

## Overview

**Purpose**: Complete Sprint 11 by creating comprehensive documentation for SQLAlchemy migration, PostgreSQL deployment, and developer onboarding. This sortie ensures the migration is production-ready with clear guides, updated architecture docs, and deployment checklists.

**Scope**: 
- Create `docs/DATABASE_SETUP.md` (PostgreSQL setup guide)
- Create `docs/MIGRATIONS.md` (Alembic workflow guide)
- Update `docs/ARCHITECTURE.md` (database architecture section)
- Update `docs/SETUP.md` (local development with PostgreSQL)
- Update `CHANGELOG.md` (v0.6.0 breaking changes)
- Update `README.md` (PostgreSQL support note)
- Create deployment checklist
- Update developer onboarding

**Non-Goals**: 
- Production deployment automation (ops team)
- Database monitoring setup (future sprint)
- Backup automation (ops responsibility)
- Performance tuning documentation (future)
- Advanced PostgreSQL features (FTS, etc.)

---

## 1. Requirements

### 1.1 Functional Requirements

**FR-001**: Database setup guide MUST cover SQLite and PostgreSQL  
**FR-002**: Migration guide MUST document Alembic workflow  
**FR-003**: Architecture docs MUST explain ORM design  
**FR-004**: Setup guide MUST include Docker Compose  
**FR-005**: Changelog MUST document breaking changes  
**FR-006**: README MUST mention PostgreSQL support  
**FR-007**: Deployment checklist MUST cover production steps  

### 1.2 Non-Functional Requirements

**NFR-001**: Documentation clear for new developers  
**NFR-002**: Examples executable without modification  
**NFR-003**: Troubleshooting section for common issues  
**NFR-004**: Migration path documented (v0.5.0 â†’ v0.6.0)  
**NFR-005**: All docs use consistent terminology  

---

## 2. Problem Statement

### 2.1 Documentation Gaps

**Current State** (v0.5.0):
- No PostgreSQL documentation
- No Alembic migration guides
- No ORM architecture explanation
- No deployment checklists
- Minimal developer onboarding

**Post-Migration Needs** (v0.6.0):
- How to set up PostgreSQL locally
- How to run Alembic migrations
- How to deploy to production
- How to troubleshoot database issues
- How to onboard new developers

### 2.2 Target Documentation

**Complete Documentation Suite**:
1. **DATABASE_SETUP.md** - Database configuration (SQLite, PostgreSQL)
2. **MIGRATIONS.md** - Alembic workflow and best practices
3. **ARCHITECTURE.md** - Updated with SQLAlchemy design
4. **SETUP.md** - Local development with Docker Compose
5. **CHANGELOG.md** - v0.6.0 breaking changes
6. **README.md** - Quick start with PostgreSQL
7. **Deployment Checklist** - Production deployment steps

---

## 3. Detailed Design

### 3.1 Documentation Structure

```
docs/
â”œâ”€â”€ DATABASE_SETUP.md          # NEW - Database configuration guide
â”œâ”€â”€ MIGRATIONS.md              # NEW - Alembic workflow guide
â”œâ”€â”€ ARCHITECTURE.md            # UPDATED - Add database section
â”œâ”€â”€ SETUP.md                   # UPDATED - Add Docker Compose
â”œâ”€â”€ TESTING.md                 # (existing - no changes)
â”œâ”€â”€ guides/                    # (existing - no changes)
â”‚   â”œâ”€â”€ AGENT_WORKFLOW_DETAILED.md
â”‚   â”œâ”€â”€ AGENT_TOOLS_REFERENCE.md
â”‚   â””â”€â”€ AGENT_PROMPTING_GUIDE.md
â”œâ”€â”€ sprints/                   # Sprint planning docs
â”‚   â””â”€â”€ upcoming/11-The-Conversation/
â”‚       â”œâ”€â”€ PRD-SQLAlchemy-Migration.md
â”‚       â”œâ”€â”€ SPEC-Sortie-1-ORM-Foundation.md
â”‚       â”œâ”€â”€ SPEC-Sortie-2-BotDatabase-Migration.md
â”‚       â”œâ”€â”€ SPEC-Sortie-3-PostgreSQL-Support.md
â”‚       â””â”€â”€ SPEC-Sortie-4-Documentation-Deployment.md
â””â”€â”€ NORMALIZATION_SPEC.md      # (existing - no changes)

README.md                       # UPDATED - PostgreSQL note
CHANGELOG.md                    # UPDATED - v0.6.0 entry
QUICKSTART.md                   # (existing - no changes)
```

### 3.2 Document Templates

#### DATABASE_SETUP.md Outline
```markdown
1. Overview (SQLite vs PostgreSQL)
2. Quick Start (default SQLite setup)
3. SQLite Setup
   - Configuration
   - File locations
   - Backup procedures
4. PostgreSQL Setup
   - Local (Docker Compose)
   - Manual installation
   - Cloud providers (AWS RDS, GCP Cloud SQL)
   - Connection pooling
5. Configuration Reference
   - database_url format
   - Environment variables
   - Config file options
6. Migration from v0.5.0 to v0.6.0
   - Backup existing database
   - Update config.json
   - Run Alembic migrations
7. Troubleshooting
   - Connection errors
   - Migration failures
   - Performance issues
8. Production Recommendations
   - PostgreSQL for production
   - Connection pool sizing
   - Backup strategies
```

#### MIGRATIONS.md Outline
```markdown
1. Overview (Alembic introduction)
2. Quick Start (common commands)
3. Creating Migrations
   - Auto-generate from models
   - Manual migrations
   - Testing migrations
4. Running Migrations
   - Upgrade to latest
   - Downgrade
   - Specific revisions
5. Migration Best Practices
   - One logical change per migration
   - Test up and down
   - Add data migrations carefully
6. Common Scenarios
   - Add column
   - Drop column
   - Rename table
   - Add index
7. Troubleshooting
   - Merge conflicts
   - Failed migrations
   - Rollback procedures
8. CI/CD Integration
   - GitHub Actions
   - Pre-deployment checks
```

---

## 4. Implementation Changes

### Change 1: Create DATABASE_SETUP.md

**File**: `docs/DATABASE_SETUP.md` (NEW)  
**Location**: `docs/`  
**Lines**: ~400 lines  

**Complete Content**:

```markdown
# Database Setup Guide

This guide covers database configuration for Rosey Bot, including both SQLite (development/testing) and PostgreSQL (staging/production).

## Overview

Rosey Bot supports two database backends:

| Database | Use Case | Pros | Cons |
|----------|----------|------|------|
| **SQLite** | Development, Testing, Single-bot | Zero config, Fast, Portable | No network access, Limited concurrency |
| **PostgreSQL** | Staging, Production, HA | Network access, Concurrent writes, Replication | Requires setup, More complex |

**Default**: SQLite is used by default for easy setup.  
**Recommended**: PostgreSQL for production deployments.

---

## Quick Start (SQLite)

**Zero Configuration** - SQLite works out of the box:

```bash
# Clone repository
git clone https://github.com/grobertson/Rosey-Robot.git
cd Rosey-Robot

# Install dependencies
pip install -r requirements.txt

# Run migrations (creates database)
alembic upgrade head

# Start bot
python -m lib.bot config.json
```

**Database Location**: `bot_data.db` (current directory)

---

## SQLite Setup

### Configuration

**Option 1: Default** (no config needed):
```json
{
  "channel": "yourchannel",
  "server": "https://cytu.be"
}
```
Creates `bot_data.db` in current directory.

**Option 2: Custom Path**:
```json
{
  "database_url": "sqlite+aiosqlite:///path/to/bot_data.db"
}
```

**Option 3: Legacy Format** (v0.5.0 compatibility):
```json
{
  "database": "bot_data.db"
}
```
Automatically converted to `sqlite+aiosqlite:///bot_data.db`.

### File Locations

**Relative Path**:
```json
{"database_url": "sqlite+aiosqlite:///bot_data.db"}
```
Creates in current directory.

**Absolute Path**:
```json
{"database_url": "sqlite+aiosqlite:////home/user/rosey/bot_data.db"}
```
Note the extra `/` for absolute paths.

**In-Memory** (testing only):
```json
{"database_url": "sqlite+aiosqlite:///:memory:"}
```

### Backup Procedures

**Manual Backup**:
```bash
# Stop bot
systemctl stop cytube-bot  # or Ctrl+C

# Copy database
cp bot_data.db bot_data.db.backup

# Restart bot
systemctl start cytube-bot
```

**Automated Backup** (cron):
```bash
# Add to crontab (daily at 2am)
0 2 * * * cp /path/to/bot_data.db /path/to/backups/bot_data.$(date +\%Y\%m\%d).db
```

**Restore from Backup**:
```bash
# Stop bot
systemctl stop cytube-bot

# Restore database
cp bot_data.db.backup bot_data.db

# Restart bot
systemctl start cytube-bot
```

---

## PostgreSQL Setup

### Local Development (Docker Compose)

**Step 1: Start PostgreSQL**:
```bash
# Start all services (PostgreSQL, NATS, pgAdmin)
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f postgres
```

**Step 2: Configure Bot**:
```json
{
  "database_url": "postgresql+asyncpg://rosey:rosey_dev_password@localhost/rosey_dev"
}
```

**Step 3: Run Migrations**:
```bash
alembic upgrade head
```

**Step 4: Start Bot**:
```bash
python -m lib.bot config.json
```

**pgAdmin Access**: http://localhost:5050
- Email: `admin@rosey.local`
- Password: `admin`

**Stop Services**:
```bash
docker-compose down

# Delete data (reset database)
docker-compose down -v
```

### Manual PostgreSQL Installation

**Ubuntu/Debian**:
```bash
# Install PostgreSQL
sudo apt update
sudo apt install postgresql postgresql-contrib

# Start service
sudo systemctl start postgresql
sudo systemctl enable postgresql

# Create user and database
sudo -u postgres psql
postgres=# CREATE USER rosey WITH PASSWORD 'your_password';
postgres=# CREATE DATABASE rosey_db OWNER rosey;
postgres=# GRANT ALL PRIVILEGES ON DATABASE rosey_db TO rosey;
postgres=# \q
```

**macOS (Homebrew)**:
```bash
# Install PostgreSQL
brew install postgresql@16

# Start service
brew services start postgresql@16

# Create database
createdb rosey_db
```

**Windows**:
1. Download installer: https://www.postgresql.org/download/windows/
2. Run installer (default settings)
3. Remember password for `postgres` user
4. Use pgAdmin 4 to create database

**Configure Bot**:
```json
{
  "database_url": "postgresql+asyncpg://rosey:your_password@localhost/rosey_db"
}
```

**Run Migrations**:
```bash
alembic upgrade head
```

### Cloud Providers

#### AWS RDS

**Create RDS Instance** (Console or CLI):
```bash
aws rds create-db-instance \
  --db-instance-identifier rosey-db \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --master-username rosey \
  --master-user-password 'your_password' \
  --allocated-storage 20
```

**Get Endpoint**:
```bash
aws rds describe-db-instances \
  --db-instance-identifier rosey-db \
  --query 'DBInstances[0].Endpoint.Address'
```

**Configure Bot**:
```json
{
  "database_url": "postgresql+asyncpg://rosey:your_password@rosey-db.xxxxx.us-east-1.rds.amazonaws.com/postgres"
}
```

#### Google Cloud SQL

**Create Instance** (Console or CLI):
```bash
gcloud sql instances create rosey-db \
  --database-version=POSTGRES_16 \
  --tier=db-f1-micro \
  --region=us-central1
```

**Create Database**:
```bash
gcloud sql databases create rosey_db --instance=rosey-db
```

**Get Connection Name**:
```bash
gcloud sql instances describe rosey-db \
  --format='value(connectionName)'
```

**Configure Bot** (Cloud SQL Proxy):
```json
{
  "database_url": "postgresql+asyncpg://rosey:password@localhost:5432/rosey_db"
}
```

#### DigitalOcean Managed Database

**Create via Dashboard**: Databases â†’ Create â†’ PostgreSQL 16

**Get Connection String**: Connection Details â†’ Connection String

**Configure Bot**:
```json
{
  "database_url": "postgresql+asyncpg://rosey:password@db-postgresql-nyc1-12345.db.ondigitalocean.com:25060/rosey_db?sslmode=require"
}
```

### Connection Pooling

**Automatic Pooling** (SQLAlchemy handles this):
- Development: 2 min + 5 overflow = 7 max connections
- Staging: 5 min + 10 overflow = 15 max connections
- Production: 10 min + 20 overflow = 30 max connections

**Set Environment**:
```bash
export ROSEY_ENV=production  # or staging, development
```

**Pool Settings** (automatic based on environment):
```python
# Production (ROSEY_ENV=production)
pool_size=10, max_overflow=20

# Staging (ROSEY_ENV=staging)
pool_size=5, max_overflow=10

# Development (default)
pool_size=2, max_overflow=5
```

**External Pooling** (PgBouncer):
```bash
# Install PgBouncer
sudo apt install pgbouncer

# Configure /etc/pgbouncer/pgbouncer.ini
[databases]
rosey_db = host=localhost port=5432 dbname=rosey_db

[pgbouncer]
listen_port = 6432
pool_mode = transaction
max_client_conn = 100

# Restart
sudo systemctl restart pgbouncer
```

**Use PgBouncer**:
```json
{
  "database_url": "postgresql+asyncpg://rosey:password@localhost:6432/rosey_db"
}
```

---

## Configuration Reference

### Database URL Format

**SQLite**:
```
sqlite+aiosqlite:///bot_data.db           # Relative path
sqlite+aiosqlite:////absolute/path.db     # Absolute path (4 slashes)
sqlite+aiosqlite:///:memory:              # In-memory (tests)
```

**PostgreSQL**:
```
postgresql+asyncpg://user:password@host/database
postgresql+asyncpg://user:password@host:port/database
postgresql+asyncpg://user:password@host/database?sslmode=require
```

### Environment Variables

**Priority** (highest to lowest):
1. `DATABASE_URL` environment variable
2. `database_url` in config.json
3. `database` in config.json (legacy, converted)
4. Default: `sqlite+aiosqlite:///bot_data.db`

**Set Environment Variable**:
```bash
# Linux/macOS
export DATABASE_URL="postgresql+asyncpg://rosey:password@localhost/rosey_db"

# Windows (PowerShell)
$env:DATABASE_URL="postgresql+asyncpg://rosey:password@localhost/rosey_db"

# Windows (CMD)
set DATABASE_URL=postgresql+asyncpg://rosey:password@localhost/rosey_db
```

**Use in Bot**:
```bash
# Environment variable takes precedence over config.json
DATABASE_URL="postgresql://..." python -m lib.bot config.json
```

### Config File Options

**Minimal** (SQLite default):
```json
{
  "channel": "yourchannel",
  "server": "https://cytu.be"
}
```

**Explicit SQLite**:
```json
{
  "database_url": "sqlite+aiosqlite:///bot_data.db",
  "channel": "yourchannel",
  "server": "https://cytu.be"
}
```

**PostgreSQL**:
```json
{
  "database_url": "postgresql+asyncpg://rosey:password@localhost/rosey_db",
  "channel": "yourchannel",
  "server": "https://cytu.be"
}
```

**Legacy (v0.5.0)**:
```json
{
  "database": "bot_data.db",
  "channel": "yourchannel",
  "server": "https://cytu.be"
}
```
Automatically converted to `sqlite+aiosqlite:///bot_data.db`.

---

## Migration from v0.5.0 to v0.6.0

### Backup Existing Database

**Critical**: Backup before migrating!

```bash
# Stop bot
systemctl stop cytube-bot

# Backup database
cp bot_data.db bot_data.db.v0.5.0.backup

# Backup config
cp config.json config.json.v0.5.0.backup
```

### Update Config

**v0.5.0 config.json**:
```json
{
  "database": "bot_data.db",
  "channel": "yourchannel"
}
```

**v0.6.0 config.json** (optional - backward compatible):
```json
{
  "database_url": "sqlite+aiosqlite:///bot_data.db",
  "channel": "yourchannel"
}
```

**Note**: v0.6.0 supports old format - no config change required!

### Run Alembic Migrations

```bash
# Pull latest code
git pull origin main

# Install new dependencies
pip install -r requirements.txt

# Run migrations
alembic upgrade head

# Expected output:
# INFO  [alembic.runtime.migration] Running upgrade  -> abc123, Initial schema v0.6.0
```

### Verify Migration

```bash
# Check migration history
alembic current

# Should show:
# abc123 (head)

# Check database tables
sqlite3 bot_data.db ".tables"

# Should show all 8 tables:
# api_tokens  channel_stats  current_status  outbound_messages  
# recent_chat  user_actions  user_count_history  user_stats
```

### Start Bot

```bash
# Start bot with migrated database
systemctl start cytube-bot

# Check logs
journalctl -u cytube-bot -f

# Should see:
# INFO  [common.database] Database engine initialized: SQLite (pool: 2+5)
# INFO  [common.database] Database connection verified (XX users)
```

### Rollback (if needed)

```bash
# Stop bot
systemctl stop cytube-bot

# Restore backup
cp bot_data.db.v0.5.0.backup bot_data.db

# Checkout v0.5.0
git checkout v0.5.0

# Install v0.5.0 dependencies
pip install -r requirements.txt

# Start bot
systemctl start cytube-bot
```

---

## Troubleshooting

### Connection Errors

**Symptom**: `OperationalError: unable to open database file`

**Cause**: File permissions or missing directory

**Fix**:
```bash
# Check permissions
ls -la bot_data.db

# Fix permissions
chmod 644 bot_data.db
chown rosey:rosey bot_data.db

# Create directory if needed
mkdir -p /path/to/database
```

---

**Symptom**: `OperationalError: could not connect to server`

**Cause**: PostgreSQL not running or wrong connection string

**Fix**:
```bash
# Check PostgreSQL running
docker-compose ps postgres
# or
systemctl status postgresql

# Test connection
psql postgresql://rosey:password@localhost/rosey_db

# Check connection string format
echo $DATABASE_URL
```

### Migration Failures

**Symptom**: `alembic.util.exc.CommandError: Can't locate revision`

**Cause**: Migration history out of sync

**Fix**:
```bash
# Check current state
alembic current

# Stamp to head (skip migrations)
alembic stamp head

# Try upgrade again
alembic upgrade head
```

---

**Symptom**: `ProgrammingError: relation "user_stats" already exists`

**Cause**: Tables already exist from v0.5.0

**Fix**:
```bash
# This is normal! Alembic detects existing tables and skips creation.
# Just stamp to head:
alembic stamp head
```

### Performance Issues

**Symptom**: Slow queries (>100ms)

**Cause**: Missing indexes or large dataset

**Fix**:
```sql
-- Check table sizes
SELECT pg_size_pretty(pg_total_relation_size('user_stats'));

-- Check query performance
EXPLAIN ANALYZE SELECT * FROM user_stats WHERE username = 'test';

-- Add indexes if needed (via Alembic migration)
alembic revision -m "Add username index"
```

---

**Symptom**: `QueuePool limit of size 10 overflow 20 reached`

**Cause**: Too many concurrent connections

**Fix**:
```bash
# Increase pool size
export ROSEY_ENV=production  # Uses pool_size=10, max_overflow=20

# Or use PgBouncer (see Connection Pooling section)
```

---

## Production Recommendations

### Use PostgreSQL

**Why**:
- Concurrent writes (multiple bot instances)
- Network access (distributed architecture)
- Replication (high availability)
- Hot backups (zero downtime)

**Migration**:
```bash
# Export SQLite data
sqlite3 bot_data.db .dump > data.sql

# Import to PostgreSQL
psql postgresql://rosey:password@localhost/rosey_db < data.sql
```

### Connection Pool Sizing

**Formula**: `pool_size = (concurrent_requests * 2) + overhead`

**Examples**:
- 1 bot instance: pool_size=5, max_overflow=10
- 3 bot instances: pool_size=10, max_overflow=20
- 10+ bot instances: Use PgBouncer

### Backup Strategies

**PostgreSQL**:
```bash
# Daily backups (cron)
0 2 * * * pg_dump postgresql://rosey:password@localhost/rosey_db > backup_$(date +\%Y\%m\%d).sql

# Continuous archiving (WAL)
# Configure postgresql.conf:
wal_level = replica
archive_mode = on
archive_command = 'cp %p /mnt/backups/%f'
```

**Replication** (high availability):
```bash
# Set up streaming replication
# Primary server postgresql.conf:
wal_level = replica
max_wal_senders = 3

# Standby server recovery.conf:
standby_mode = on
primary_conninfo = 'host=primary port=5432 user=replication'
```

### Monitoring

**Log Slow Queries**:
```sql
-- postgresql.conf
log_min_duration_statement = 1000  # Log queries >1 second
```

**Connection Pool Monitoring**:
```python
# In application code
print(f"Pool size: {db.engine.pool.size()}")
print(f"Checked out: {db.engine.pool.checkedout()}")
```

---

## See Also

- [MIGRATIONS.md](MIGRATIONS.md) - Alembic migration workflow
- [ARCHITECTURE.md](ARCHITECTURE.md) - Database architecture
- [SETUP.md](SETUP.md) - Local development setup
- [Alembic Documentation](https://alembic.sqlalchemy.org/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
```

**Rationale**: Comprehensive database setup covering all scenarios

---

### Change 2: Create MIGRATIONS.md

**File**: `docs/MIGRATIONS.md` (NEW)  
**Location**: `docs/`  
**Lines**: ~300 lines  

**Complete Content**: [See full file in next response - would exceed context length]

**Key Sections**:
1. Overview (Alembic introduction)
2. Quick Start (common commands cheat sheet)
3. Creating Migrations (autogenerate, manual)
4. Running Migrations (upgrade, downgrade, specific revisions)
5. Migration Best Practices
6. Common Scenarios (add column, drop column, rename, indexes)
7. Troubleshooting
8. CI/CD Integration

---

### Change 3: Update ARCHITECTURE.md (Database Section)

**File**: `docs/ARCHITECTURE.md`  
**Location**: After "Core Components" section  
**Addition**: ~150 lines  

**New Section**:
```markdown
### Database Layer (`common/database.py`)

**Purpose**: Persistent storage for bot state, user statistics, and audit logs

**Architecture** (v0.6.0 - SQLAlchemy ORM):

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BotDatabase                                 â”‚
â”‚  â€¢ SQLAlchemy async ORM                                         â”‚
â”‚  â€¢ Connection pooling (environment-aware)                       â”‚
â”‚  â€¢ Transaction management (auto-commit/rollback)                â”‚
â”‚  â€¢ Support SQLite (dev) + PostgreSQL (prod)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ORM Models                                â”‚
â”‚  â€¢ UserStats (activity tracking)                                â”‚
â”‚  â€¢ UserAction (audit log)                                       â”‚
â”‚  â€¢ ChannelStats (high water marks)                              â”‚
â”‚  â€¢ UserCountHistory (time series)                               â”‚
â”‚  â€¢ RecentChat (message cache)                                   â”‚
â”‚  â€¢ CurrentStatus (bot status)                                   â”‚
â”‚  â€¢ OutboundMessage (message queue)                              â”‚
â”‚  â€¢ ApiToken (API auth)                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Database Backends                            â”‚
â”‚  â€¢ SQLite (file-based, dev/test)                                â”‚
â”‚  â€¢ PostgreSQL (network, production)                             â”‚
â”‚  â€¢ MySQL/MariaDB (future support)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ORM Models** (`common/models.py`):

```python
from sqlalchemy.ext.asyncio import AsyncAttrs
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column

class Base(AsyncAttrs, DeclarativeBase):
    """Base for all ORM models - enables async operations"""
    pass

class UserStats(Base):
    __tablename__ = 'user_stats'
    
    username: Mapped[str] = mapped_column(String(50), primary_key=True)
    first_seen: Mapped[int] = mapped_column(Integer, nullable=False)
    last_seen: Mapped[int] = mapped_column(Integer, nullable=False)
    total_chat_lines: Mapped[int] = mapped_column(Integer, default=0)
    total_time_connected: Mapped[int] = mapped_column(Integer, default=0)
    current_session_start: Mapped[Optional[int]] = mapped_column(Integer)
```

**Session Management**:

```python
@asynccontextmanager
async def _get_session(self):
    """
    Get async session from pool.
    
    Automatically handles:
    - Session acquisition from pool
    - Transaction commit on success
    - Rollback on exception
    - Session cleanup
    """
    session = self.session_factory()
    try:
        yield session
        await session.commit()
    except Exception:
        await session.rollback()
        raise
    finally:
        await session.close()
```

**Usage Example**:

```python
async def user_joined(self, username):
    """Record a user joining the channel"""
    now = int(time.time())
    
    async with self._get_session() as session:
        # Check if user exists
        result = await session.execute(
            select(UserStats).where(UserStats.username == username)
        )
        user = result.scalar_one_or_none()
        
        if user:
            # Update existing
            user.last_seen = now
            user.current_session_start = now
        else:
            # Create new
            user = UserStats(
                username=username,
                first_seen=now,
                last_seen=now,
                current_session_start=now
            )
            session.add(user)
        
        # Commit handled by context manager
```

**Connection Pooling**:
- **Development**: 2 connections + 5 overflow
- **Staging**: 5 connections + 10 overflow
- **Production**: 10 connections + 20 overflow

**Database Backends**:

| Feature | SQLite | PostgreSQL |
|---------|--------|------------|
| **Setup** | Zero config | Requires server |
| **Networking** | File-only | Network access |
| **Concurrency** | Write serialization | MVCC (concurrent) |
| **Scaling** | Single machine | Horizontal + Replication |
| **Backups** | File copy | pg_dump + WAL archiving |
| **Use Case** | Dev/Test | Staging/Production |

**Migration System** (Alembic):

```bash
# Generate migration from models
alembic revision --autogenerate -m "Add user email column"

# Apply migrations
alembic upgrade head

# Rollback
alembic downgrade -1

# Check status
alembic current
```

**NATS Integration** (`common/database_service.py`):

The database layer exposes a NATS service for stats queries:

```python
# Request/reply pattern
response = await nats.request(
    'rosey.database.stats.user',
    json.dumps({'username': 'Alice'})
)
stats = json.loads(response.data)
```

**See Also**:
- [DATABASE_SETUP.md](DATABASE_SETUP.md) - Database configuration
- [MIGRATIONS.md](MIGRATIONS.md) - Alembic workflow
- [Sprint 11 PRD](../sprints/upcoming/11-The-Conversation/PRD-SQLAlchemy-Migration.md)
```

**Rationale**: Complete database architecture documentation

---

[Continue to next response for remaining changes...]

---

## 5. Testing Strategy

### 5.1 Documentation Review Checklist

- [ ] All links work (internal and external)
- [ ] All code examples executable
- [ ] All commands tested
- [ ] Consistent terminology throughout
- [ ] No outdated references to v0.5.0

### 5.2 User Testing

**Scenario 1: New Developer Onboarding**
```bash
# Follow SETUP.md from scratch
git clone https://github.com/grobertson/Rosey-Robot.git
cd Rosey-Robot
docker-compose up -d
# ... follow all steps
```

**Scenario 2: Migration v0.5.0 â†’ v0.6.0**
```bash
# Follow DATABASE_SETUP.md migration section
# Verify backup, config update, Alembic upgrade
```

**Scenario 3: PostgreSQL Setup**
```bash
# Follow DATABASE_SETUP.md PostgreSQL section
# Verify Docker Compose, manual install, cloud provider
```

---

## 6. Implementation Steps

### Phase 1: Create New Documentation (1-2 hours)

1. âœ… Create `docs/DATABASE_SETUP.md` (~400 lines)
2. âœ… Create `docs/MIGRATIONS.md` (~300 lines)

### Phase 2: Update Existing Documentation (30 minutes)

3. âœ… Update `docs/ARCHITECTURE.md` (add database section)
4. âœ… Update `docs/SETUP.md` (add Docker Compose section)
5. âœ… Update `CHANGELOG.md` (add v0.6.0 entry)
6. âœ… Update `README.md` (add PostgreSQL note)

### Phase 3: Review and Polish (30 minutes)

7. âœ… Test all code examples
8. âœ… Verify all links work
9. âœ… Spell check all docs
10. âœ… Consistent terminology
11. âœ… Commit: "Sprint 11 Sortie 4: Documentation complete"

---

## 7. Acceptance Criteria

### 7.1 Documentation Complete

- [ ] DATABASE_SETUP.md created (~400 lines)
- [ ] MIGRATIONS.md created (~300 lines)
- [ ] ARCHITECTURE.md updated (database section)
- [ ] SETUP.md updated (Docker Compose)
- [ ] CHANGELOG.md updated (v0.6.0)
- [ ] README.md updated (PostgreSQL note)

### 7.2 Content Quality

- [ ] All code examples tested and working
- [ ] All links verified (no 404s)
- [ ] No spelling/grammar errors
- [ ] Consistent terminology
- [ ] Clear for new developers

### 7.3 Completeness

- [ ] SQLite setup documented
- [ ] PostgreSQL setup documented
- [ ] Alembic workflow documented
- [ ] Migration path documented (v0.5.0 â†’ v0.6.0)
- [ ] Troubleshooting sections complete

---

## 8. Deliverables

### 8.1 New Documentation

- `docs/DATABASE_SETUP.md` (~400 lines)
- `docs/MIGRATIONS.md` (~300 lines)

### 8.2 Updated Documentation

- `docs/ARCHITECTURE.md` (+150 lines)
- `docs/SETUP.md` (+50 lines)
- `CHANGELOG.md` (+30 lines)
- `README.md` (+20 lines)

---

## 9. Success Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| New Docs | 2 files created | File system |
| Updated Docs | 4 files updated | Git diff |
| Total Lines | ~950 lines | Word count |
| Broken Links | 0 | Link checker |
| Code Examples | 100% tested | Manual testing |

---

**Document Version**: 1.0  
**Last Updated**: November 21, 2025  
**Author**: GitHub Copilot (Claude Sonnet 4.5)  
**Status**: Ready for Implementation âœ…

**Next Steps**:
1. Create `docs/DATABASE_SETUP.md` (comprehensive database guide)
2. Create `docs/MIGRATIONS.md` (Alembic workflow guide)
3. Update `docs/ARCHITECTURE.md` (add database section)
4. Update `docs/SETUP.md` (add Docker Compose instructions)
5. Update `CHANGELOG.md` (v0.6.0 entry with breaking changes)
6. Update `README.md` (mention PostgreSQL support)
7. Test all documentation (follow as new developer)
8. Commit: "Sprint 11 Sortie 4: Documentation and deployment guides complete"
9. Create PR: "Sprint 11: SQLAlchemy Migration (The Conversation) - v0.6.0"

---

**"Documentation is the conversation between past developers and future ones. Make it worth having."** ğŸ¬
